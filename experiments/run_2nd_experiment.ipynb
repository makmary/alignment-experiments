{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cced67e",
   "metadata": {},
   "source": [
    "## SECOND EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec93ca9",
   "metadata": {},
   "source": [
    "Для второго эксперимента мы использовали подход, представленный по этой [ссылке](https://colmap.github.io/faq.html#reconstruct-sparse-dense-model-from-known-camera-poses) в документации COLMAP. \n",
    "\n",
    "Суть данного эксперимента заключается в том, что мы будем использовать возможности аппарата PixSfM, а именно featuremetric KA до построения SfM и feature-reference BA после построения SfM.\n",
    "\n",
    "\n",
    "### Reconstruct sparse/dense model from known camera poses \n",
    "\n",
    "| COLMAP | PixSfM | \n",
    "| --- | --- |\n",
    "| 1)  Создать три файла cameras.txt, images.txt, point3D.txt в одной папке. | 1) Создать три файла cameras.txt, images.txt, point3D.txt в одной папке |\n",
    "| 2) Создать пустой файл points3D.txt | 2) Создать пустой файл points3D.txt |\n",
    "| 3) В файле images.txt каждая вторая строка для изображения должна быть пустой, cameras.txt должен иметь всю инфу. | 3) В файле images.txt каждая вторая строка для изображения должна быть пустой, cameras.txt должен иметь всю инфу. |\n",
    "| 4) Заполняем БД инфой о камерах и изображениях. | 4) Заполняем БД инфой о камерах и изображениях.|\n",
    "| 5) Выполняем feature extraction при помощи COLMAP и записываем фичи в БД. | 5)  Выполняем feature extraction при помощи **hloc**.|\n",
    "| 6) Выполняем exhausting matching. | 6) Выполняем exhausting matching при помощи **hloc**.|\n",
    "| | 7) Выполняем **Featuremetric KA** (Keypoint Adjustment), запись улучшенных features в БД. |\n",
    "| 7) Построение SfM (этап triangulation).| 8) Построение SfM (этап triangulation).|\n",
    "|  | 9) Выполняем **feature-reference BA** (Bundle Adjustment).|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dde385",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b290853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "\n",
    "from pathlib import Path\n",
    "import pycolmap\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/pixel-perfect-sfm/\")\n",
    "sys.path.append(\"/workspace/pixel-perfect-sfm/Hierarchical-Localization\")\n",
    "\n",
    "from hloc import extract_features, match_features, reconstruction, pairs_from_exhaustive, visualization\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils.viz_3d import init_figure, plot_points, plot_reconstruction, plot_camera_colmap\n",
    "from hloc.utils.read_write_model import  write_next_bytes, Point3D, Image, read_images_text, \\\n",
    "        read_points3D_binary, write_points3D_binary, write_images_binary, read_images_binary, \\\n",
    "        read_cameras_text\n",
    "\n",
    "from pixsfm.util.visualize import init_image, plot_points2D\n",
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm import ostream_redirect\n",
    "\n",
    "from utils import modified_write_points3D_text\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import open3d as o3d\n",
    "assert o3d.__version__ == '0.15.2', 'The version 0.15.2 is required!'\n",
    "\n",
    "# redirect the C++ outputs to notebook cells\n",
    "cpp_out = ostream_redirect(stderr=True, stdout=True)\n",
    "cpp_out.__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549546dd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1dda1",
   "metadata": {},
   "source": [
    "В **object_name** необходимо задать имя объекта, над которым вы хотите провести эксперимент.\n",
    "\n",
    "**check_for_calibrated_images** - булевая переменная, по которой мы выбираем какие поз камер использовать (менее точные (True) или точные (False))\n",
    "\n",
    "**delete_previous_output** - если True, то удаляет все предыдущие файлы в папке outputs. Использовать супер осторожно.\n",
    "\n",
    "**has_cache** - если True, то у Вас уже существует файл с feature maps и он сохранен в папке cache_init. Это файл с feature maps Вы получаете только тогда, когда вы уже сделали featuremetric KA или BA для одного из ваших экспериментов.\n",
    "\n",
    "**show_visualization** - если True, то показывает визуализацию результата эксперимента (3d pointcloud, задектированные keypoints (features) и final reprojections для какого-то изображения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = 'dragon'\n",
    "\n",
    "check_for_calibrated_images = False\n",
    "delete_previous_output = False\n",
    "\n",
    "has_cache = True\n",
    "show_visualization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cb231",
   "metadata": {},
   "source": [
    "**images_init** - путь к файлу images.txt с известными позами камер (каждая вторая строка пустая)\n",
    "\n",
    "**calibrated_images_init** - путь к файлу images.txt c известнами позами камер (но менее точные)\n",
    "\n",
    "**cameras_init** - путь к файлу cameras.txt\n",
    "\n",
    "**images** - путь к папке с изображениями для реконструкции\n",
    "\n",
    "**outputs** - путь к папке со всеми результатами\n",
    "\n",
    "**cache_init** - путь к кэш-файлу, его мы получаем во время того, когда делаем KA или BA. В этот файле хранятся featuremaps после  dense feature extraction. В среднем на одну картинку размером 2368х1952 уходит 3 минуты. Этот файл вообще нельзя трогать, поэтому мы копируем его в папку outputs для своего эксперимента и продолжаем работу.\n",
    "\n",
    "**cache_path** - тот же файл, что cache_init, с которым мы теперь будем работать во время эксперимента.\n",
    "\n",
    "**sfm_pairs** - файл с названиями пар изображений на каждой строке\n",
    "\n",
    "**features** - файл с features для каждой картинки, извлеченными при помощи feature_conf\n",
    "\n",
    "**matches** - файл с matches для каждой пары картинок, извлеченными при помощи matcher_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf226a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/workspace')\n",
    "\n",
    "images_init = root / f'datasets/sk3d/dataset/{object_name}/tis_right/rgb/images.txt'\n",
    "calibrated_images_init = root / 'datasets/sk3d/dataset/calibration/tis_right/rgb/images.txt' # менее точные\n",
    "\n",
    "cameras_init = root / 'datasets/sk3d/dataset/calibration/tis_right/rgb/cameras.txt'\n",
    "\n",
    "images = root / f'datasets/sk3d/dataset/{object_name}/tis_right/rgb/undistorted/ambient@best'\n",
    "\n",
    "outputs = root / f'pixel-perfect-sfm/outputs/{object_name}_exp2/'\n",
    "\n",
    "if delete_previous_output:\n",
    "    !rm -rf $outputs \n",
    "    \n",
    "outputs.mkdir(parents=True, exist_ok=True)    \n",
    "    \n",
    "if has_cache:\n",
    "    cache_init = root / f'pixel-perfect-sfm/outputs/caches/{object_name}/s2dnet_featuremaps_sparse.h5'\n",
    "    !cp -r $cache_init $outputs\n",
    "    cache_path = outputs / 's2dnet_featuremaps_sparse.h5'    \n",
    "\n",
    "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
    "features = outputs / 'features.h5'\n",
    "matches = outputs / 'matches.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915c30f",
   "metadata": {},
   "source": [
    "**exp2_dir** - папка, в которой будет сохранен результат второго эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa180d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_dir = outputs / \"exp2\"\n",
    "exp2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if check_for_calibrated_images:\n",
    "    images_init = calibrated_images_init\n",
    "    \n",
    "    exp2_dir = outputs / \"calibrated/exp2\"\n",
    "    exp2_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea1bd2",
   "metadata": {},
   "source": [
    "# 3D mapping and refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00bc9cd",
   "metadata": {},
   "source": [
    "Здесь описаны возможности для настройки [**extract_features**](https://github.com/cvg/Hierarchical-Localization/blob/91f40bfd765add3b59ba7376f8579d8829f7fa78/hloc/extract_features.py#L21)\n",
    "\n",
    "Здесь описаны возможности для настройки [**match_features**](https://github.com/cvg/Hierarchical-Localization/blob/91f40bfd765add3b59ba7376f8579d8829f7fa78/hloc/match_features.py#L17)\n",
    "\n",
    "Здесь описан пайплайн того, как можно использовать свои кастомные [**local features**, **matcher**, **image retrieval**](https://github.com/cvg/Hierarchical-Localization/tree/91f40bfd765add3b59ba7376f8579d8829f7fa78#using-your-own-local-features-or-matcher).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39562de4",
   "metadata": {},
   "source": [
    "Здесь мы проверяем какие изображения мы будем использовать для реконструкции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [str(p.relative_to(images)) for p in images.iterdir()]\n",
    "print(len(references), \"mapping images\")\n",
    "plot_images([read_image(images / r) for r in references[:4]], dpi=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895fb0a5",
   "metadata": {},
   "source": [
    "**extract_features** - данная функция получает на вход *feature_conf*, *images* (путь к папке с изображениями), *image_list* (список тех изображений, которые вы хотите использовать для feature exctraction), *feature_path* (путь к файлу, где будет сохранен результат). На выходе получаем файл (**features**) с извлеченными features. Если **features** существует, то пропускается.\n",
    "\n",
    "**pairs_from_exhaustive** - данная функция получает на вход *sfm_pairs* (путь к файлу, где будет сохранен результат), *image_list* (список тех изображений, при помощи которых вы сделаете exhaustive pairs.) На выходе получаем файл (**sfm_pairs**) с парами изображений.  Если **sfm_pairs** существует, то пропускается.\n",
    "\n",
    "**match_features** - данная функция получает на вход *matcher_conf*, *sfm_pairs* (путь к файлу, где хранятся пары изображений после exhaustive pairing), *features* (путь к файлу, где хранятся извлеченный features для каждого изображения), *matches* (путь к файлу, где хранятся matches для каждой пары изображения). На выходе получаем файл (**matches**) с matches для каждой пары изображений . Если **match_features** существует, то пропускается.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ae0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /workspace/pixel-perfect-sfm/outputs/dragon/features.h5 $outputs\n",
    "!cp -r /workspace/pixel-perfect-sfm/outputs/dragon/matches.h5 $outputs\n",
    "!cp -r /workspace/pixel-perfect-sfm/outputs/dragon/pairs-sfm.txt $outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67896b21",
   "metadata": {},
   "source": [
    "Ниже клетка может выполняться от получаса до часа (в зависимости от нагруженности).\n",
    "\n",
    "Features extraction - 1 минута.\n",
    "\n",
    "Features matching - 35-50 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e01db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(feature_conf, images, image_list=references, feature_path=features) \n",
    "pairs_from_exhaustive.main(sfm_pairs, image_list=references)\n",
    "match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5201d02",
   "metadata": {},
   "source": [
    "Копируем файлы images.txt, cameras.txt в папку для второго эксперимента. В этой папке мы должны иметь три файла (images.txt, cameras.txt и пустой файл point3d.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38448a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r $images_init $exp2_dir\n",
    "print(\"images.txt copied!\")\n",
    "\n",
    "!cp -r $cameras_init $exp2_dir\n",
    "print(\"cameras.txt copied!\")\n",
    "\n",
    "!touch $exp2_dir/points3D.txt\n",
    "print(\"points3D.txt created!\")\n",
    "\n",
    "!ls $exp2_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdc6ec",
   "metadata": {},
   "source": [
    "Смотрим при помощи **pycolmap** информацию о полученной на данной момент реконструкции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb96238",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = pycolmap.Reconstruction(exp2_dir)\n",
    "print(check_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c24a69",
   "metadata": {},
   "source": [
    "**Featuremetric KA (Keypoint Adjustment)**\n",
    "\n",
    "В конфиге conf_KA расписана необходимая информация для того, чтобы сделать KA. В этом конфиге также указано, что вы хотите использовать cache, который находится в пути cache_path.\n",
    "\n",
    "**keypoints_path** -  здесь будут сохранены обновленная информация по уже имеющимся keypoints (features). После KA тут уже будут сохранены новые features.\n",
    "\n",
    "Здесь описано как можно настроить конфигурацию для КА. https://github.com/cvg/pixel-perfect-sfm#detailed-configuration\n",
    "\n",
    " КА выполняется ниже за 3-4 минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm.refine_colmap import PixSfM as PixSfM_ba\n",
    "\n",
    "# running Keypoint Adjustment\n",
    "conf_KA = {\n",
    "        \"dense_features\": {\n",
    "                \"use_cache\": True,\n",
    "        },\n",
    "        \"KA\": {\n",
    "            \"dense_features\": {'use_cache': True}, \n",
    "            \"split_in_subproblems\": True,\n",
    "            \"max_kps_per_problem\": 1000,  \n",
    "        },\n",
    "}\n",
    "\n",
    "if not has_cache:\n",
    "    conf_KA.update({\n",
    "        \"dense_features\": {\n",
    "            \"use_cache\": True,\n",
    "            \"sparse\" : True,\n",
    "            \"dtype\" : \"half\",\n",
    "            \"overwrite_cache\": True,\n",
    "            \"load_cache_on_init\": False,\n",
    "            \"patch_size\": 8,\n",
    "            \"cache_format\": \"chunked\"\n",
    "        }\n",
    "\n",
    "    })\n",
    "\n",
    "refiner = PixSfM(conf=conf_KA)\n",
    "\n",
    "keypoints_path = exp2_dir / \"refined_keypoints.h5\"\n",
    "\n",
    "keypoints, ka_data, feature_manager = refiner.refine_keypoints(\n",
    "    output_path = keypoints_path,\n",
    "    image_dir = images,\n",
    "    features_path = features,\n",
    "    pairs_path = sfm_pairs,\n",
    "    matches_path = matches,\n",
    "    cache_path = cache_path,\n",
    ")\n",
    "\n",
    "if not has_cache:    \n",
    "    caches = root / f'pixel-perfect-sfm/outputs/caches/exp2/{object_name}'\n",
    "    caches.mkdir(parents=True, exist_ok=True)\n",
    "    cache_path = outputs / 's2dnet_featuremaps_sparse.h5'\n",
    "    !cp -r $cache_path $caches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39cf6b",
   "metadata": {},
   "source": [
    "Импортируем **hloc**. Она нам поможет создать БД, заполнить БД, сделать геометрическую верификацию, сделать триангуляцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cvg/pixel-perfect-sfm/blob/main/pixsfm/refine_hloc.py\n",
    "\n",
    "try:\n",
    "    import hloc\n",
    "except ImportError:\n",
    "    print(\"Could not import hloc.\")\n",
    "    hloc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3577fc",
   "metadata": {},
   "source": [
    "1) Создание БД\n",
    "\n",
    "2) Импорт камер, картинок, улучшенных features, matches\n",
    "\n",
    "3) Запись реконструкции до FMBA в папку.\n",
    "\n",
    "Ниже клетка выполняется за 1 минуту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_path = exp2_dir / 'hloc'\n",
    "hloc_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "database_path = hloc_path / 'database.db' \n",
    "reference = pycolmap.Reconstruction(exp2_dir)   \n",
    "\n",
    "images_txt_path = exp2_dir / 'images.txt'\n",
    "images_dict = read_images_text(images_txt_path)\n",
    "        \n",
    "# Here I changed code and in database we have data about camera extrinsics    \n",
    "image_ids = hloc.triangulation.create_db_from_model(reference, \n",
    "                                                    database_path, \n",
    "                                                    images_dict)\n",
    "\n",
    "#Importing features into database -> keypoints table \n",
    "hloc.triangulation.import_features(image_ids, \n",
    "                                   database_path, \n",
    "                                   keypoints_path)\n",
    "\n",
    "#Importing matches into database -> matches table\n",
    "skip_geometric_verification = False\n",
    "hloc.triangulation.import_matches(image_ids, \n",
    "                                  database_path, \n",
    "                                  sfm_pairs, \n",
    "                                  matches,\n",
    "                                  min_match_score=None, \n",
    "                                  skip_geometric_verification=skip_geometric_verification)\n",
    "\n",
    "verbose, estimate_two_view_geometries = True, False\n",
    "\n",
    "if not skip_geometric_verification:\n",
    "        if estimate_two_view_geometries:\n",
    "            hloc.triangulation.estimation_and_geometric_verification(database_path, \n",
    "                                                                     sfm_pairs, \n",
    "                                                                     verbose)\n",
    "        else:\n",
    "            # We are doing this part to add data to two_view_geometries table\n",
    "            hloc.triangulation.geometric_verification(\n",
    "                image_ids, \n",
    "                reference, \n",
    "                database_path, \n",
    "                keypoints_path, \n",
    "                sfm_pairs, \n",
    "                matches)\n",
    "            \n",
    "reconstruction = hloc.triangulation.run_triangulation(hloc_path, \n",
    "                                                      database_path, \n",
    "                                                      images, \n",
    "                                                      reference, \n",
    "                                                      verbose)\n",
    "\n",
    "print(reconstruction.summary())  \n",
    "\n",
    "# Saving result to a folder\n",
    "reconstruction.write(str(hloc_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42acb97",
   "metadata": {},
   "source": [
    "Проверяем те же ли параметры камер получились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70497f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare images old and new, compare cameras old and new\n",
    "images_old = read_images_text(exp2_dir / 'images.txt')\n",
    "images_new = read_images_binary(hloc_path / 'images.bin')\n",
    "\n",
    "for i in range(1, 101):\n",
    "    assert np.array_equal(images_old[i].tvec, images_new[i].tvec) == True\n",
    "    assert np.allclose(np.array(images_old[i].qvec, dtype=np.float32), \n",
    "                          np.array(images_new[i].qvec, dtype=np.float32)) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9195496",
   "metadata": {},
   "source": [
    "**Featuremetric BA (Bundle Adjustment)**\n",
    "\n",
    "В конфиге conf_BA расписана необходимая информация для того, чтобы сделать BA. В этом конфиге также указано, что вы хотите использовать cache, который находится в пути cache_path.\n",
    "\n",
    "Здесь описано как настроить конфигурацию для ВА. https://github.com/cvg/pixel-perfect-sfm#detailed-configuration\n",
    "\n",
    "Здесь ВА выполняется за 1.5-2 минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running featuremetric BA\n",
    "conf_BA = {\n",
    "        \"dense_features\": {\n",
    "                \"use_cache\": True,\n",
    "        },\n",
    "        \n",
    "        \"BA\": {\n",
    "            \"dense_features\": {'use_cache': True}, \n",
    "            \"apply\": True\n",
    "        }\n",
    "}\n",
    "\n",
    "refiner = PixSfM_ba(conf=conf_BA)\n",
    "\n",
    "reconstruction, ba_data, feature_manager2 = refiner.refine_reconstruction(\n",
    "    output_path = exp2_dir / 'hloc/model',\n",
    "    input_path = exp2_dir / 'hloc',\n",
    "    image_dir = images,\n",
    "    cache_path = cache_path,\n",
    ")\n",
    "\n",
    "print(reconstruction.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea076263",
   "metadata": {},
   "source": [
    "Перевод модели в формат TXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $exp2_dir/hloc/model/model_txt/\n",
    "\n",
    "!colmap model_converter \\\n",
    "    --input_path $exp2_dir/hloc/model \\\n",
    "    --output_path $exp2_dir/hloc/model/model_txt/\\\n",
    "    --output_type TXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184f026",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = init_figure()\n",
    "\n",
    "args = dict(max_reproj_error=3.0, \n",
    "            min_track_length=2, \n",
    "            cs=0.01) #camera size\n",
    "plot_reconstruction(fig3d, reconstruction, \n",
    "                    color='rgba(0, 255, 0, 0.5)', \n",
    "                    name=\"refined\", **args)\n",
    "if show_visualization:\n",
    "    fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined = reconstruction\n",
    "\n",
    "img = refined.images[refined.reg_image_ids()[0]]\n",
    "cam = refined.cameras[img.camera_id]\n",
    "\n",
    "fig = init_image(images / img.name)    \n",
    "\n",
    "plot_points2D(fig, [p2D.xy for p2D in img.points2D if p2D.has_point3D()])\n",
    "plot_points2D(fig, cam.world_to_image(img.project(refined)), color='rgba(255, 0, 0, 0.5)')\n",
    "\n",
    "if show_visualization:\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
