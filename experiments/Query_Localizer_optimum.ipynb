{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac535ce1",
   "metadata": {},
   "source": [
    "## QUERY LOCALIZER EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ce2f5",
   "metadata": {},
   "source": [
    "Целью данного эксперимента является нахождение позы нового изображения на основе уже имеющейся реконструкции SfM. Здесь описан пайплайн, когда мы сами создаем SfM при помощи аппрата PixSfM. Вы можете также использовать уже готовую SfM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc43ded",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "\n",
    "from pathlib import Path\n",
    "import pycolmap\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/workspace/pixel-perfect-sfm/\")\n",
    "sys.path.append(\"/workspace/pixel-perfect-sfm/Hierarchical-Localization\")\n",
    "\n",
    "from hloc import extract_features, match_features, reconstruction, pairs_from_exhaustive, visualization\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils.viz_3d import init_figure, plot_points, plot_reconstruction, plot_camera_colmap\n",
    "from hloc.utils.read_write_model import  write_next_bytes, Point3D, Image, read_images_text, read_points3D_binary,\\\n",
    "        write_points3D_binary, write_images_binary, read_images_binary, write_images_text, read_cameras_binary, \\\n",
    "        Camera, write_cameras_text, read_cameras_text\n",
    "\n",
    "from pixsfm.util.visualize import init_image, plot_points2D\n",
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm import ostream_redirect\n",
    "\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "from utils import modified_write_images_text\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "assert o3d.__version__ == '0.15.2', 'The version 0.15.2 is required!'\n",
    "\n",
    "# redirect the C++ outputs to notebook cells\n",
    "cpp_out = ostream_redirect(stderr=True, stdout=True)\n",
    "cpp_out.__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b855460",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f07db",
   "metadata": {},
   "source": [
    "В **object_name** необходимо задать имя объекта, над которым вы хотите провести эксперимент.\n",
    "\n",
    "**check_for_calibrated_images** - булевая переменная, по которой мы выбираем какие поз камер использовать (менее точные (True) или точные (False))\n",
    "\n",
    "**delete_previous_output** - если True, то удаляет все предыдущие файлы в папке outputs. Использовать супер осторожно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1deaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = 'dragon'\n",
    "\n",
    "check_for_calibrated_images = False\n",
    "delete_previous_output = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4b312",
   "metadata": {},
   "source": [
    "**images_all** - путь к папке со всеми изображениями\n",
    "\n",
    "**outputs** - путь к папке со всеми результатами\n",
    "\n",
    "**cache_init** - путь к кэш-файлу, его мы получаем во время того, когда делаем KA или BA. В этот файле хранятся featuremaps после  dense feature extraction. В среднем на одну картинку размером 2368х1952 уходит 3 минуты. Этот файл вообще нельзя трогать, поэтому мы копируем его в папку outputs для своего эксперимента и продолжаем работу.\n",
    "\n",
    "**cache_path** - тот же файл, что cache_init, с которым мы теперь будем работать во время эксперимента.\n",
    "\n",
    "**sfm_pairs** - файл с названиями пар изображений на каждой строке\n",
    "\n",
    "**features** - файл с features для каждой картинки, извлеченными при помощи feature_conf\n",
    "\n",
    "**matches** - файл с matches для каждой пары картинок, извлеченными при помощи matcher_conf\n",
    "\n",
    "**pairs-loc.txt** - файл с названиями пар изображений на каждой строке (только на этот раз идут пары для картинок из ДБ со всеми возможными картинками из папки query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/workspace')\n",
    "\n",
    "images_all = root / f'datasets/sk3d/dataset/{object_name}/tis_right/rgb/undistorted/ambient@best'\n",
    "\n",
    "images_init = root / f'datasets/sk3d/dataset/{object_name}/tis_right/rgb/images.txt'\n",
    "cameras_init = root / 'datasets/sk3d/dataset/calibration/tis_right/rgb/cameras.txt'\n",
    "\n",
    "outputs = root / (f'pixel-perfect-sfm/outputs/{object_name}/query_localizer_optimum')\n",
    "\n",
    "if delete_previous_output:\n",
    "    !rm -rf $outputs\n",
    "    \n",
    "outputs.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
    "features = outputs / 'features.h5'\n",
    "matches = outputs / 'matches.h5'\n",
    "loc_pairs = outputs / 'pairs-loc.txt'\n",
    "\n",
    "exp_loc = outputs / \"query_localizer_v1\"\n",
    "exp_loc.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c46467",
   "metadata": {},
   "source": [
    "# 3D mapping and refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee283a3",
   "metadata": {},
   "source": [
    "Здесь описаны возможности для настройки [**extract_features**](https://github.com/cvg/Hierarchical-Localization/blob/91f40bfd765add3b59ba7376f8579d8829f7fa78/hloc/extract_features.py#L21)\n",
    "\n",
    "Здесь описаны возможности для настройки [**match_features**](https://github.com/cvg/Hierarchical-Localization/blob/91f40bfd765add3b59ba7376f8579d8829f7fa78/hloc/match_features.py#L17)\n",
    "\n",
    "Здесь описан пайплайн того, как можно использовать свои кастомные [**local features**, **matcher**, **image retrieval**](https://github.com/cvg/Hierarchical-Localization/tree/91f40bfd765add3b59ba7376f8579d8829f7fa78#using-your-own-local-features-or-matcher).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa594d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79842a7d",
   "metadata": {},
   "source": [
    "## Create db and query images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a39e8",
   "metadata": {},
   "source": [
    "Создаем две папки: mapping и query. В папке mapping будут лежать все те картинки, которые нужны нам для построения реконструкции.  В папке query будут находиться все те картинки, для которых мы хотим новую позы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = root / f'pixel-perfect-sfm/dataset/{object_name}_loc_opt'\n",
    "images.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_extra = root / f'pixel-perfect-sfm/dataset/{object_name}_loc_opt/extra'\n",
    "!rm -rf $images_extra\n",
    "\n",
    "images_extra.mkdir(parents=True, exist_ok = True)\n",
    "\n",
    "images_references = root / f'pixel-perfect-sfm/dataset/{object_name}_loc_opt/mapping'\n",
    "!rm -rf $images_references\n",
    "images_references.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_queries = root / f'pixel-perfect-sfm/dataset/{object_name}_loc_opt/query'\n",
    "!rm -rf $images_queries\n",
    "images_queries.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "ref_num = 3\n",
    "img_list = sorted([str(p) for p in images_all.iterdir()])\n",
    "\n",
    "for fn in img_list[ref_num:100]: shutil.copy(fn, str(images_extra)) \n",
    "    \n",
    "for fn in img_list[0:ref_num]: shutil.copy(fn, str(images_references))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f87b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"All image references: \" && ls $images_references\n",
    "!echo \"All image queries: \" && ls $images_queries\n",
    "!echo \"All image extra: \" && ls $images_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_cams = read_cameras_text(str(cameras_init))\n",
    "f, cx, cy, k = _cams[0].params\n",
    "\n",
    "# https://github.com/colmap/colmap/blob/dev/src/base/camera_models.h#L201\n",
    "\n",
    "opts = dict(camera_model='PINHOLE', camera_params=','.join(map(str, (f, cx, cy, k))))\n",
    "\n",
    "mapper_opts = dict(ba_refine_focal_length=False, \n",
    "                       ba_refine_extra_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a134bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import hloc\n",
    "except ImportError:\n",
    "    print(\"Could not import hloc.\")\n",
    "    hloc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_triangulation(exp_loc: Path,\n",
    "                      keypoints_path: Path, \n",
    "                      sfm_pairs: Path,\n",
    "                      matches: Path,\n",
    "                      images_references: Path,\n",
    "                     ) -> pycolmap.Reconstruction:\n",
    "\n",
    "    hloc_path = exp_loc / 'hloc'\n",
    "    hloc_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    database_path = hloc_path / 'database.db' \n",
    "    reference = pycolmap.Reconstruction(exp_loc)   \n",
    "\n",
    "    images_dict = read_images_text(exp_loc / 'images.txt')\n",
    "\n",
    "    # Here I changed code and in database we have data about camera extrinsics    \n",
    "    image_ids = hloc.triangulation.create_db_from_model(reference, \n",
    "                                                        database_path, \n",
    "                                                        images_dict)\n",
    "\n",
    "    #Importing features into database -> keypoints table \n",
    "    hloc.triangulation.import_features(image_ids, \n",
    "                                       database_path, \n",
    "                                       keypoints_path)\n",
    "\n",
    "    #Importing matches into database -> matches table\n",
    "    skip_geometric_verification = False\n",
    "    hloc.triangulation.import_matches(image_ids, \n",
    "                                      database_path, \n",
    "                                      sfm_pairs, \n",
    "                                      matches,\n",
    "                                      min_match_score=None, \n",
    "                                      skip_geometric_verification=skip_geometric_verification)\n",
    "\n",
    "    verbose, estimate_two_view_geometries = False, False\n",
    "\n",
    "    if not skip_geometric_verification:\n",
    "            if estimate_two_view_geometries:\n",
    "                hloc.triangulation.estimation_and_geometric_verification(database_path, \n",
    "                                                                         sfm_pairs, \n",
    "                                                                         verbose)\n",
    "            else:\n",
    "                # We are doing this part to add data to two_view_geometries table\n",
    "                hloc.triangulation.geometric_verification(\n",
    "                    image_ids, \n",
    "                    reference, \n",
    "                    database_path, \n",
    "                    keypoints_path, \n",
    "                    sfm_pairs, \n",
    "                    matches)\n",
    "\n",
    "    reconstruction = hloc.triangulation.run_triangulation(hloc_path, \n",
    "                                                          database_path, \n",
    "                                                          images_references, \n",
    "                                                          reference, \n",
    "                                                          verbose)\n",
    "\n",
    "    print('Finished the triangulation with statistics:\\n%s',\n",
    "                reconstruction.summary())\n",
    "\n",
    "    # Saving result to a folder\n",
    "    reconstruction.write(str(hloc_path))\n",
    "\n",
    "#     !mkdir -p $hloc_path/model_txt/\n",
    "\n",
    "#     !colmap model_converter \\\n",
    "#         --input_path $hloc_path \\\n",
    "#         --output_path $hloc_path/model_txt/\\\n",
    "#         --output_type TXT\n",
    "    \n",
    "    return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf04b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_KA = {\n",
    "            \"dense_features\": {\n",
    "                    \"use_cache\": False,\n",
    "            },\n",
    "            \"KA\": {\n",
    "                \"dense_features\": {'use_cache': True}, \n",
    "                \"split_in_subproblems\": True,\n",
    "                \"max_kps_per_problem\": 1000,  \n",
    "            },\n",
    "    }\n",
    "\n",
    "def run_featuremetric_KA(exp_loc: Path, \n",
    "                         images_references: Path, \n",
    "                         features: Path, \n",
    "                         sfm_pairs: Path, \n",
    "                         matches: Path) -> Path:\n",
    "\n",
    "    keypoints_path = exp_loc / \"refined_keypoints.h5\"\n",
    "    refiner = PixSfM(conf=conf_KA)\n",
    "\n",
    "    keypoints, ka_data, feature_manager = refiner.refine_keypoints(\n",
    "        output_path = keypoints_path,\n",
    "        image_dir = images_references,\n",
    "        features_path = features,\n",
    "        pairs_path = sfm_pairs,\n",
    "        matches_path = matches,\n",
    "    )\n",
    "    \n",
    "    return keypoints_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_BA = {\n",
    "            \"dense_features\": {\n",
    "                    \"use_cache\": False,\n",
    "            },\n",
    "            \"BA\": { \n",
    "                    \"apply\": True,\n",
    "                    \"optimizer\": {\n",
    "                          \"refine_focal_length\": False,  # whether to optimize the focal length\n",
    "                          \"refine_principal_point\": False,  # whether to optimize the principal points\n",
    "                          \"refine_extra_params\": False,  # whether to optimize distortion parameters\n",
    "                          \"refine_extrinsics\": False,  # whether to optimize the camera poses\n",
    "                    }\n",
    "                }\n",
    "}\n",
    "\n",
    "def run_featuremetric_BA(exp_loc: Path, \n",
    "                         images_references: Path,\n",
    "                         mapper_options: Optional[Dict[str, Any]] = None):\n",
    "    \n",
    "    # running featuremetric BA\n",
    "    hloc_args = dict(camera_mode=pycolmap.CameraMode.SINGLE,\n",
    "                    verbose=False,\n",
    "                    image_options=mapper_options)\n",
    "\n",
    "    sfm = PixSfM_ba(conf=conf_BA)\n",
    "\n",
    "    model, ba_data, feature_manager = sfm.refine_reconstruction(\n",
    "        output_path = exp_loc / 'hloc/model',\n",
    "        input_path = exp_loc / 'hloc',\n",
    "        image_dir = images_references,\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    !colmap model_converter \\\n",
    "        --input_path $exp_loc/hloc/model/ \\\n",
    "        --output_path $exp_loc/hloc/model/ \\\n",
    "        --output_type TXT\n",
    "    \n",
    "    return model, feature_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29de116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pixsfm.refine_hloc import PixSfM\n",
    "from pixsfm.refine_colmap import PixSfM as PixSfM_ba\n",
    "import pycolmap\n",
    "from pixsfm.localize import QueryLocalizer, pose_from_cluster\n",
    "\n",
    "result_dir = exp_loc / 'result'\n",
    "result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "extra_imgs_sorted = sorted(list(images_extra.iterdir()))\n",
    "all_init_imgs_dict = read_images_text(images_init)\n",
    "\n",
    "all_result = {}\n",
    "cameras_dict = {}\n",
    "result_queries = {}\n",
    "db_imgs_sfm = {}\n",
    "\n",
    "#Iterate through every image in extra_images folder\n",
    "for i, img in enumerate(extra_imgs_sorted):\n",
    "\n",
    "    # 1) 2 images copied in db\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"Base images in db:\")\n",
    "        !ls $images_references\n",
    "    \n",
    "    # 2) Copy 1 image to query folder\n",
    "    \n",
    "    query_name = Path(img).stem + '.png'\n",
    "    shutil.copy(str(img), str(images_queries))\n",
    "    print(f\"Image {query_name} is copied to {images_queries}\")\n",
    "    \n",
    "    ####### References list updated\n",
    "    reference_images = [str(p.relative_to(images_references)) for p in images_references.iterdir()]\n",
    "    len_db_images = len(reference_images)\n",
    "    print(\"Reference images: \", len(reference_images), \n",
    "          reference_images\n",
    "         )  \n",
    "\n",
    "    ####### Queries list updated\n",
    "    query_images = [str(p.relative_to(images_queries)) for p in images_queries.iterdir()]\n",
    "    print(\"Query images: \", len(query_images), \n",
    "         query_images\n",
    "         )  \n",
    "    \n",
    "    # 3) Find image pairs for Sfm and Match features between each other\n",
    "    \n",
    "    args = dict(overwrite=True) if result_queries else {}  \n",
    "    \n",
    "    extract_features.main(feature_conf, \n",
    "                      images_references, \n",
    "                      image_list=reference_images, \n",
    "                      feature_path=features,\n",
    "                      **args)\n",
    "    \n",
    "    pairs_from_exhaustive.main(sfm_pairs, \n",
    "                               image_list=reference_images)\n",
    "    \n",
    "    match_features.main(matcher_conf, \n",
    "                        sfm_pairs, \n",
    "                        features=features, \n",
    "                        matches=matches, \n",
    "                        **args);\n",
    "    \n",
    "    dst_file = str(exp_loc / 'images.txt')\n",
    "    if os.path.exists(dst_file):\n",
    "        !rm -r $dst_file\n",
    "    !cp -r $images_init $exp_loc        \n",
    "    print(\"images.txt copied!\")\n",
    "\n",
    "    dst_file = str(exp_loc / 'cameras.txt')\n",
    "    if os.path.exists(dst_file):\n",
    "        !rm -r $dst_file\n",
    "    !cp -r $cameras_init $exp_loc\n",
    "    print(\"cameras.txt copied!\")\n",
    "\n",
    "    !touch $exp_loc/points3D.txt\n",
    "    print(\"points3D.txt created!\")\n",
    "\n",
    "    !ls -la $exp_loc\n",
    "    \n",
    "    insert = 0\n",
    "    for k, img in all_init_imgs_dict.items():\n",
    "        if insert == ref_num:\n",
    "            break\n",
    "        if img.name in reference_images:\n",
    "            db_imgs_sfm[k] = img\n",
    "            insert += 1\n",
    "\n",
    "    \n",
    "    # 4) Build SfM \n",
    "    \n",
    "    if result_queries:\n",
    "        # SfM + new results\n",
    "        print(\"Get images and cameras to update initial SfM (SfM + queries).\")\n",
    "        images_dict_prev = read_images_text(str(exp_loc / 'hloc/model/images.txt'))\n",
    "        db_imgs_sfm = {**images_dict_prev,**result_queries}\n",
    "        \n",
    "        modified_write_images_text(db_imgs_sfm, exp_loc / 'images.txt')\n",
    "        \n",
    "    else:     \n",
    "        # initial SfM\n",
    "        print(\"Get images and cameras for initial SfM.\")\n",
    "        write_images_text(db_imgs_sfm, exp_loc / 'images.txt')    \n",
    "        cameras_dict = read_cameras_text(exp_loc / 'cameras.txt')   \n",
    "        \n",
    "    keypoints_path = run_featuremetric_KA(exp_loc=exp_loc, \n",
    "                                          images_references=images_references, \n",
    "                                          features=features, \n",
    "                                          sfm_pairs=sfm_pairs, \n",
    "                                          matches=matches)\n",
    "    \n",
    "\n",
    "    model_KA = run_triangulation(exp_loc=exp_loc, \n",
    "                     keypoints_path=keypoints_path, \n",
    "                     sfm_pairs=sfm_pairs, \n",
    "                     matches=matches, \n",
    "                     images_references=images_references)\n",
    "\n",
    "    model_BA, feature_manager = run_featuremetric_BA(exp_loc=exp_loc, \n",
    "                                                  images_references=images_references,\n",
    "                                                  mapper_options=mapper_opts)\n",
    "    \n",
    "    # 5) Extract features for query image\n",
    "    \n",
    "    features_query = outputs / 'features_query.h5'\n",
    "    !rm -rf $features_query \n",
    "    \n",
    "    matches_query = outputs / 'matches_query.h5'\n",
    "    !rm -rf $matches_query\n",
    "\n",
    "    extract_features.main(feature_conf, \n",
    "                          images_queries, \n",
    "                          image_list=query_images, \n",
    "                          feature_path=features_query)\n",
    "    \n",
    "    references_registered = [model_BA.images[i].name for i in model_BA.reg_image_ids()]\n",
    "\n",
    "    pairs_from_exhaustive.main(loc_pairs, \n",
    "                           image_list=query_images, \n",
    "                           ref_list=references_registered)\n",
    "    \n",
    "    match_features.main(matcher_conf, \n",
    "                        loc_pairs, \n",
    "                        features=features_query, \n",
    "                        matches=matches_query, \n",
    "                        features_ref=features);\n",
    "       \n",
    "    \n",
    "    # 6) Run pose localization\n",
    "    \n",
    "    ref_ids = [model_BA.find_image_with_name(r).image_id for r in references_registered]\n",
    "    \n",
    "    loc_conf = {\n",
    "        #\"dense_features\": model_BA.conf.dense_features, \n",
    "        # same features as the SfM refinement\n",
    "        \"PnP\": {  # initial pose estimation with PnP+RANSAC\n",
    "            'estimation': {'ransac': {'max_error': 12.0}},\n",
    "            'refinement': {'refine_focal_length': False, \n",
    "                           'refine_extra_params': False},\n",
    "        },\n",
    "        \"QBA\": {  # query pose refinement\n",
    "            \"optimizer:\": {'refine_focal_length': False, \n",
    "                           'refine_extra_params': False},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    localizer = QueryLocalizer(model_BA, \n",
    "                               conf=loc_conf, \n",
    "                               dense_features=feature_manager)\n",
    "    \n",
    "    \n",
    "    _cams = read_cameras_binary(str(exp_loc / 'hloc/model/cameras.bin'))\n",
    "    cam_info = _cams[0]\n",
    "\n",
    "    pinhole_camera = pycolmap.Camera(\n",
    "                                model='PINHOLE',\n",
    "                                width=cam_info.width,\n",
    "                                height=cam_info.height,\n",
    "                                params=cam_info.params)\n",
    "\n",
    "    print(\"Camera info --> \", pinhole_camera)\n",
    "\n",
    "\n",
    "    # 7) Save results from experiment (we got new pose for query image here) and delete file with results \n",
    "    \n",
    "    ret, log = pose_from_cluster(localizer, \n",
    "                             query_name, \n",
    "                             pinhole_camera, \n",
    "                             ref_ids, \n",
    "                             features_query, \n",
    "                             matches_query, \n",
    "                             image_path=images_queries / query_name)\n",
    "    \n",
    "    print(f\"ret --> {query_name}\", ret['qvec'], ret['tvec'], ret['camera'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    image_id = int(Path(query_name).stem) + 1\n",
    "    \n",
    "    result_queries[image_id] = Image(\n",
    "                id=image_id, \n",
    "                qvec=ret['qvec'], \n",
    "                tvec=ret['tvec'],\n",
    "                camera_id=cam_info.id, \n",
    "                name=query_name,\n",
    "                xys= np.array([]), \n",
    "                point3D_ids= np.array([]),\n",
    "    )\n",
    "    \n",
    "    # 9) Delete query from query folder\n",
    "    query_to_delete = images_queries / query_name\n",
    "    query_to_delete.unlink()  \n",
    "    \n",
    "    # 10) Copy this query image to db folder for next iteration run\n",
    "    shutil.copy(str(images_all / query_name), str(images_references))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
